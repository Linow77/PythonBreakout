{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GlobalBreakout.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Création du jeu"
      ],
      "metadata": {
        "id": "6BTM8r30OJjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation des bibliothèques"
      ],
      "metadata": {
        "id": "XDXrn-D6MN1L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx_eQ4FpMGfV",
        "outputId": "31e0cd23-20ef-4b44-f714-dfab294482c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.7/dist-packages (2.1.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.43.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: tf-agents[reverb] in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.0.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.15.0)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.19.5)\n",
            "Requirement already satisfied: gym>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.17.3)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (1.13.3)\n",
            "Requirement already satisfied: tensorflow-probability>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.15.0)\n",
            "Requirement already satisfied: dm-reverb~=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (0.6.1)\n",
            "Requirement already satisfied: tensorflow~=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-agents[reverb]) (2.7.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from dm-reverb~=0.6.0->tf-agents[reverb]) (0.1.6)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.7/dist-packages (from dm-reverb~=0.6.0->tf-agents[reverb]) (1.3.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf-agents[reverb]) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf-agents[reverb]) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17.0->tf-agents[reverb]) (0.16.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (1.43.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (2.7.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (13.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (2.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (2.7.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.7.0->tf-agents[reverb]) (0.24.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.7.0->tf-agents[reverb]) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow~=2.7.0->tf-agents[reverb]) (3.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.14.1->tf-agents[reverb]) (4.4.2)\n"
          ]
        }
      ],
      "source": [
        "#Installation\n",
        "!sudo apt-get update\n",
        "!pip install pygame\n",
        "!pip install tensorflow\n",
        "!pip install tf-agents[reverb]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import des modules"
      ],
      "metadata": {
        "id": "TPyah480MRbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pygame\n",
        "import random as r\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "#TensorFlow\n",
        "import tensorflow as tf\n",
        "from tf_agents.environments import tf_environment\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "from tf_agents.networks import actor_distribution_network\n",
        "from tf_agents.agents.reinforce import reinforce_agent\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.utils import common\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.policies import py_tf_eager_policy\n",
        "\n",
        "#Reverb\n",
        "import reverb\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer\n",
        "from tf_agents.replay_buffers import reverb_utils"
      ],
      "metadata": {
        "id": "Me8j3DHbMRsH"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Création des classes"
      ],
      "metadata": {
        "id": "NS96Qmo6MfQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class wall():\n",
        "    def __init__(self,instanceEnv):\n",
        "        ## Env Variables ##\n",
        "        self.env = instanceEnv\n",
        "\n",
        "        ## Wall Variables ##\n",
        "        # Same random seed for every creation of wall\n",
        "        r.seed(1000) #1000\n",
        "        # number of brick per row and per column\n",
        "        self.rows = 6\n",
        "        self.cols = 5\n",
        "        #Sizes\n",
        "        self.wallHeight = (self.env.height - 100) // 2\n",
        "        self.brickHeight = self.wallHeight // self.rows\n",
        "\n",
        "        #Table for storing bricks\n",
        "        self.bricks = []\n",
        "        #Number of breakable bricks\n",
        "        self.breakableBricks = 0\n",
        "        \n",
        "        # border of the bricks (gap between bricks)\n",
        "        self.border = 3\n",
        "        self.brickWidth = self.env.width // self.cols\n",
        "\n",
        "        #Save of the wall in order to reset the episode\n",
        "        self.save = []\n",
        "\n",
        "    def createBricks(self):\n",
        "        for rowNumber in range(self.rows):\n",
        "            for colNumber in range(self.cols):\n",
        "                # Create Rectancle for each brick\n",
        "                brick = pygame.Rect(\n",
        "                    colNumber*self.brickWidth, 100+rowNumber*self.brickHeight, self.brickWidth, self.brickHeight)\n",
        "                \n",
        "                # 25% unbreakable bricks\n",
        "                type = r.randint(0,3)\n",
        "                if type != 0:\n",
        "                    self.breakableBricks+=1\n",
        "\n",
        "                # Store bricks inside table\n",
        "                self.bricks.append(\n",
        "                    (colNumber, rowNumber, type, brick))\n",
        "\n",
        "                colNumber += 1\n",
        "            rowNumber += 1\n",
        "        #Save the wall \n",
        "        self.save = self.bricks.copy()\n",
        "\n",
        "    def resetBricks(self):\n",
        "        self.bricks = self.save.copy()      \n",
        "\n",
        "    def printWall(self,screen):\n",
        "        for brick in self.bricks:\n",
        "            # check for unbreakable bricks\n",
        "            if(brick[2] == 0):\n",
        "                color = self.env.color1\n",
        "            else:\n",
        "                color = self.env.color2\n",
        "            \n",
        "            # print bricks\n",
        "            pygame.draw.rect(screen, (color),\n",
        "                             ((brick[3].x + self.border), (brick[3].y + self.border), self.brickWidth - 2*self.border, self.brickHeight - 2*self.border))\n",
        "\n",
        "class paddle():\n",
        "    def __init__(self,instanceEnv):\n",
        "        ## Env Variables ##\n",
        "        self.env = instanceEnv\n",
        "\n",
        "        ## Paddle Variables ##\n",
        "        # Sizes\n",
        "        self.paddleWidth = self.env.width // 5\n",
        "        self.paddleHeight = 10\n",
        "        # Initial Position\n",
        "        self.x = (self.env.width - self.paddleWidth)/2  \n",
        "        self.y = self.env.height - 60\n",
        "        #Create teh rectangle of the paddle\n",
        "        self.rect = pygame.Rect(\n",
        "            self.x, self.y, self.paddleWidth, self.paddleHeight)\n",
        "        #Speed of the paddle\n",
        "        self.speed = 8\n",
        "\n",
        "    def printPaddle(self,screen):\n",
        "        pygame.draw.rect(screen, self.env.color3, self.rect)     \n",
        "\n",
        "    def move(self):\n",
        "        # get key pressed\n",
        "        key = pygame.key.get_pressed()\n",
        "\n",
        "        # move left\n",
        "        if key[pygame.K_LEFT] and self.rect.left > 0:\n",
        "            self.rect.x -= self.speed\n",
        "\n",
        "        # move right\n",
        "        if key[pygame.K_RIGHT] and self.rect.right < self.env.width:\n",
        "            self.rect.x += self.speed\n",
        "\n",
        "class ball():\n",
        "    def __init__(self,instanceEnv):\n",
        "        ## Env Variables ##\n",
        "        self.env = instanceEnv\n",
        "\n",
        "        ## Ball Variables ##\n",
        "        # Initial speed of the ball on each axes\n",
        "        self.ballSpeed = 2.5  # on Axes at the beginning\n",
        "        self.speedx = self.ballSpeed\n",
        "        self.speedy = -self.ballSpeed\n",
        "\n",
        "        # Global Velocity of the ball\n",
        "        self.velocity = math.sqrt(2*(self.ballSpeed**2))\n",
        "\n",
        "        # Radius of the ball\n",
        "        self.rad = 10\n",
        "\n",
        "        # Initial position of the ball\n",
        "        self.x = self.env.width // 2 - self.rad  # init position of the rectangle\n",
        "        self.y = self.env.height - 90            # init position of the rectangle\n",
        "\n",
        "        # Create a rectangle around the ball\n",
        "        self.rect = pygame.Rect(\n",
        "            self.x, self.y, 2*self.rad, 2*self.rad)\n",
        "\n",
        "        #Horizontal Direction (from the left to the right = 1)\n",
        "        self.directionH = 1\n",
        "\n",
        "        #Angle of the colision between the ball and the paddle (or the wall)\n",
        "        self.angle = -1\n",
        "        #Angle of the redirection after colision\n",
        "        self.newAngle = -1\n",
        "\n",
        "        #Save the nature of the colision (wall, screen, or paddle)\n",
        "        self.lastCollision = \"\"\n",
        "\n",
        "        # margin Error for Colisions\n",
        "        self.margin = 5\n",
        "\n",
        "    def printBall(self,screen):\n",
        "        pygame.draw.circle(screen, self.env.color3, (self.rect.x +\n",
        "                                            self.rad, self.rect.y + self.rad), self.rad)\n",
        "        \n",
        "    def move(self, paddleRect, wallBricks):\n",
        "        #reset lastCollision\n",
        "        self.lastCollision = \"\"\n",
        "\n",
        "        # Add speed every tick to the ball's coordinates\n",
        "        self.x += self.speedx\n",
        "        self.y += self.speedy\n",
        "\n",
        "        # Update the position of the ball\n",
        "        self.rect.x = self.x\n",
        "        self.rect.y = self.y\n",
        "\n",
        "        #-- Check for screen borders --#\n",
        "        # left and right borders\n",
        "        if self.rect.right > self.env.width or self.rect.left < 0:\n",
        "            self.speedx *= -1\n",
        "            #save collision for reward\n",
        "            self.lastCollision = \"sideBorder\"\n",
        "\n",
        "        # top border\n",
        "        elif self.rect.top < 0:\n",
        "            self.speedy *= -1\n",
        "            #save collision for reward\n",
        "            self.lastCollision = \"topBorder\"\n",
        "\n",
        "        # bottom border\n",
        "        elif self.rect.bottom > self.env.height:\n",
        "            #save collision for reward\n",
        "            self.lastCollision = \"endBorder\"\n",
        "\n",
        "            # reset ball position\n",
        "            self.x = self.env.width // 2 - self.rad\n",
        "            self.y = self.env.height - 90\n",
        "            self.rect.x = self.x\n",
        "            self.rect.y = self.y\n",
        "            self.speedx = self.ballSpeed\n",
        "            self.speedy = -self.ballSpeed\n",
        "\n",
        "            # reset paddle position\n",
        "            paddleRect.rect.x = (self.env.width - paddleRect.paddleWidth)/2  # init position\n",
        "\n",
        "            # get a new ball if availabe\n",
        "            if self.env.balls > 0:\n",
        "                # delete a ball\n",
        "                self.env.balls -= 1\n",
        "\n",
        "            else:  # no ball left\n",
        "                self.env._episode_ended = True\n",
        "\n",
        "        #-- End Check for screen borders --#\n",
        "\n",
        "        #-- Check for collisions between ball and paddle --#\n",
        "        elif self.rect.y > paddleRect.rect.y - 2*self.rad:\n",
        "            if self.rect.colliderect(paddleRect):\n",
        "\n",
        "                # TOP COLLISION\n",
        "                # check if ball is on top of the trail (between the 5px margin)\n",
        "                if(abs(self.rect.bottom - paddleRect.rect.y) < self.margin and self.speedy > 0):\n",
        "\n",
        "                    #save collision for reward\n",
        "                    self.lastCollision = \"top\"\n",
        "\n",
        "                    # calculate angle between the ball's path and the trail\n",
        "                    if self.speedx == 0:\n",
        "                        self.angle = 90\n",
        "                    else:\n",
        "                        self.angle = abs(math.degrees(\n",
        "                            math.atan(self.speedy/abs(self.speedx))))\n",
        "\n",
        "                    if(self.speedx > 0):\n",
        "                        self.directionH = 1  # from the left\n",
        "                    else:\n",
        "                        self.directionH = -1  # from the right\n",
        "\n",
        "                    # change x if not on the middle of the paddle\n",
        "\n",
        "                    # LEFT PART\n",
        "                    if self.rect.right >= paddleRect.rect.x and self.rect.left < paddleRect.rect.x + (0.2 * paddleRect.paddleWidth):\n",
        "\n",
        "                        if self.directionH == 1:  # from the left\n",
        "                            # increase angle by 35%\n",
        "                            if self.angle < 30:\n",
        "                                self.newAngle = self.angle*1.35\n",
        "\n",
        "                            elif self.angle > 60:  # increase angle by 25%\n",
        "                                self.newAngle = self.angle*1.25\n",
        "\n",
        "                            else:  # increase angle by 30%\n",
        "                                self.newAngle = self.angle*1.30\n",
        "\n",
        "                        else:  # from the right\n",
        "                            # reduce angle by 35%\n",
        "                            if self.angle < 30:\n",
        "                                self.newAngle = self.angle*0.65\n",
        "\n",
        "                            elif self.angle > 60:  # reduce angle by 25%\n",
        "                                self.newAngle = self.angle*0.75\n",
        "\n",
        "                            else:  # reduce angle by 30%\n",
        "                                self.newAngle = self.angle*0.70\n",
        "\n",
        "                        self.speedx = - \\\n",
        "                            (math.cos(math.radians(self.newAngle)) * self.velocity)\n",
        "                        self.speedy = - \\\n",
        "                            (math.sin(math.radians(self.newAngle)) * self.velocity)\n",
        "\n",
        "                    # MIDDLE LEFT PART\n",
        "                    elif self.rect.right >= paddleRect.rect.x + (0.2 *paddleRect.paddleWidth) and self.rect.left < paddleRect.rect.x + (0.4 *paddleRect.paddleWidth):\n",
        "\n",
        "                        if self.directionH == 1:  # from the left\n",
        "                            # increase angle by 20%\n",
        "                            if self.angle < 30:\n",
        "                                self.newAngle = self.angle*1.2\n",
        "\n",
        "                            elif self.angle > 60:  # increase angle by 10%\n",
        "                                self.newAngle = self.angle*1.1\n",
        "\n",
        "                            else:  # increase angle by 15%\n",
        "                                self.newAngle = self.angle*1.15\n",
        "\n",
        "                        else:  # from the right\n",
        "                            # reduce angle by 20%\n",
        "                            if self.angle < 30:\n",
        "                                self.newAngle = self.angle*0.8\n",
        "\n",
        "                            elif self.angle > 60:  # reduce angle by 10%\n",
        "                                self.newAngle = self.angle*0.9\n",
        "\n",
        "                            else:  # reduce angle by 15%\n",
        "                                self.newAngle = self.angle*0.85\n",
        "\n",
        "                        self.speedx = - \\\n",
        "                            (math.cos(math.radians(self.newAngle)) * self.velocity)\n",
        "                        self.speedy = - \\\n",
        "                            (math.sin(math.radians(self.newAngle)) * self.velocity)\n",
        "\n",
        "                    elif self.rect.right >= paddleRect.rect.x + (0.4 * paddleRect.paddleWidth) and self.rect.left < paddleRect.rect.x + (0.6 * paddleRect.paddleWidth):\n",
        "                        # angle is not changed\n",
        "                        self.speedy *= -1\n",
        "\n",
        "                    # MIDLE RIGHT PART\n",
        "                    elif self.rect.right >= paddleRect.rect.x + (0.6 * paddleRect.paddleWidth) and self.rect.left < paddleRect.rect.x + (0.8 * paddleRect.paddleWidth):\n",
        "\n",
        "                        if self.directionH == 1:  # from the left\n",
        "                            # reduce angle by 20%\n",
        "                            if self.angle < 30:\n",
        "                                self.newAngle = self.angle*0.8\n",
        "\n",
        "                            elif self.angle > 60:  # reduce angle by 10%\n",
        "                                self.newAngle = self.angle*0.9\n",
        "\n",
        "                            else:  # send the ball in opposite direction\n",
        "                                # reduce angle by 15%\n",
        "                                self.newAngle = self.angle*0.85\n",
        "\n",
        "                        else:  # from the right\n",
        "                            if self.angle < 30:\n",
        "                                # increase angle by 20%\n",
        "                                self.newAngle = self.angle*1.2\n",
        "\n",
        "                            elif self.angle > 60:  # increase angle by 10%\n",
        "                                self.newAngle = self.angle*1.1\n",
        "\n",
        "                            else:  # increase angle by 15%\n",
        "                                self.newAngle = self.angle*1.15\n",
        "\n",
        "                        self.speedx = \\\n",
        "                            (math.cos(math.radians(self.newAngle)) * self.velocity)\n",
        "                        self.speedy = - \\\n",
        "                            (math.sin(math.radians(self.newAngle)) * self.velocity)\n",
        "\n",
        "                    # RIGHT PART\n",
        "                    elif self.rect.right >= paddleRect.rect.x + (0.8 * paddleRect.paddleWidth) and self.rect.left < paddleRect.rect.x + paddleRect.paddleWidth:\n",
        "                        if self.directionH == 1:  # from the left\n",
        "                            # reduce angle by 35%\n",
        "                            if self.angle < 30:\n",
        "                                self.newAngle = self.angle*0.65\n",
        "\n",
        "                            elif self.angle > 60:  # reduce angle by 25%\n",
        "                                self.newAngle = self.angle*0.75\n",
        "\n",
        "                            else:  # send the ball in opposite direction\n",
        "                                # reduce angle by 30%\n",
        "                                self.newAngle = self.angle*0.70\n",
        "\n",
        "                        else:  # from the right\n",
        "                            if self.angle < 30:\n",
        "                                # increase angle by 35%\n",
        "                                self.newAngle = self.angle*1.35\n",
        "\n",
        "                            elif self.angle > 60:  # increase angle by 25%\n",
        "                                self.newAngle = self.angle*1.25\n",
        "\n",
        "                            else:  # increase angle by 30%\n",
        "                                self.newAngle = self.angle*1.30\n",
        "\n",
        "                        self.speedx = \\\n",
        "                            (math.cos(math.radians(self.newAngle)) * self.velocity)\n",
        "                        self.speedy = - \\\n",
        "                            (math.sin(math.radians(self.newAngle)) * self.velocity)\n",
        "\n",
        "                # SIDES COLLISIONS\n",
        "                else:  # collision with side\n",
        "                    #save collision for reward\n",
        "                    self.lastCollision = \"side\"\n",
        "                    if (abs(self.rect.left - paddleRect.rect.right) < self.margin):\n",
        "                        # check direction of the ball\n",
        "                        if self.speedx < 0:\n",
        "                            self.speedx *= -1\n",
        "                        else:  # if same direction as the paddle don't reverse direction but increase speed\n",
        "                            self.speedx += 3\n",
        "\n",
        "                    elif (abs(self.rect.right - paddleRect.rect.left) < self.margin):\n",
        "                        # check direction of the ball\n",
        "                        if self.speedx > 0:\n",
        "                            self.speedx *= -1\n",
        "                        else:  # if same direction as the paddle don't reverse direction but increase speed\n",
        "                            self.speedx -= 3\n",
        "\n",
        "        #-- End Check for collisions between ball and paddle --#\n",
        "\n",
        "        #-- Check for collisions between ball and Bricks --#\n",
        "        elif self.rect.y > 0 and self.rect.y < (self.env.height // 2) + 100:\n",
        "            for brick in wallBricks:\n",
        "                if(self.rect.colliderect(brick[3])):\n",
        "                    # check if collision is on top or at bottom of the brick\n",
        "                    if ((abs(self.rect.top - brick[3].bottom) < self.margin and self.speedy < 0) or\n",
        "                            (abs(self.rect.bottom - brick[3].top) < self.margin and self.speedy > 0)):\n",
        "                        # top or bottom\n",
        "                        self.speedy *= -1\n",
        "\n",
        "                    elif ((abs(self.rect.left - brick[3].right) < self.margin and self.speedx < 0) or\n",
        "                          (abs(self.rect.right - brick[3].left) < self.margin and self.speedx > 0)):\n",
        "                        # right or left\n",
        "                        self.speedx *= -1\n",
        "\n",
        "                    # delete the brick if breakable\n",
        "                    if(brick[2] != 0):\n",
        "                        wallBricks.remove(brick)\n",
        "                        #add score\n",
        "                        self.env.score+=1\n",
        "\n",
        "    def gravity(self):\n",
        "        if (self.speedy >= 0 and self.speedy < 1):  # stuck horizontally\n",
        "            self.speedy = 1\n",
        "        elif (self.speedy < 0 and self.speedy > -1):  # stuck horizontally\n",
        "            self.speedy = -1"
      ],
      "metadata": {
        "id": "p8LKsEchMfAI"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Création de l'environnement"
      ],
      "metadata": {
        "id": "6pEkGMQrMrR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BreakoutEnv(py_environment.PyEnvironment):\n",
        "  def __init__(self, visualize, fps=10000):\n",
        "    ## Init Variables ##\n",
        "    # screen size\n",
        "    self.width = 640\n",
        "    self.height = 600   \n",
        "\n",
        "    # remaining balls\n",
        "    self.balls = 2 \n",
        "\n",
        "    ## Init object ##\n",
        "    self.wall = wall(self)\n",
        "    self.paddle = paddle(self)\n",
        "    self.ball = ball(self)\n",
        "\n",
        "    # Score #\n",
        "    self.score = 0\n",
        "\n",
        "    ## Definition of actions and observation \n",
        "    #three actions : move left, move right or stand still\n",
        "    self._action_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(), dtype=np.int32, minimum=0, maximum=2, name='action')\n",
        "        \n",
        "    #observation on ball's position and paddle's position\n",
        "    self._observation_spec = array_spec.BoundedArraySpec(\n",
        "        shape=(2,), dtype=np.int32, minimum=0, maximum=self.width, name='observation')\n",
        "    #observations are stored inside self._state\n",
        "    self._state = [self.paddle.rect.x,self.ball.rect.x]\n",
        "\n",
        "    #Check if episode is ended\n",
        "    self._episode_ended = False\n",
        "\n",
        "    #Variables for Pygame\n",
        "    self.visualize = visualize \n",
        "    #Activate the visualisation\n",
        "    if(visualize==True):\n",
        "        # Create the screen\n",
        "        self.screen = None\n",
        "\n",
        "        # Create the clock\n",
        "        self.clock = pygame.time.Clock()\n",
        "        self.fps = fps\n",
        "\n",
        "        # title\n",
        "        pygame.display.set_caption('Breakout')\n",
        "\n",
        "  def action_spec(self):\n",
        "    return self._action_spec\n",
        "\n",
        "  def observation_spec(self):\n",
        "    return self._observation_spec\n",
        "\n",
        "  def _reset(self): #a faire\n",
        "    self._episode_ended = False\n",
        "    #Reset wall\n",
        "    self.wall.resetBricks()\n",
        "    #reset remainig balls\n",
        "    self.balls = 2\n",
        "    #reset score\n",
        "    self.score = 0\n",
        "\n",
        "    return ts.restart(np.array(self._state, dtype=np.int32))\n",
        "\n",
        "  def _step(self, action):\n",
        "    #Check if last action ended the episode\n",
        "    if self._episode_ended:\n",
        "      #restart a new episode\n",
        "      return self.reset()\n",
        "\n",
        "    #Move the ball\n",
        "    self.ball.move(self.paddle, self.wall.bricks)\n",
        "\n",
        "    # Apply action\n",
        "    if(action == 0 ) : #left\n",
        "        if(self.paddle.rect.x - self.paddle.speed < 0):\n",
        "            self.paddle.rect.x = 0\n",
        "        else:\n",
        "            self.paddle.rect.x -= self.paddle.speed\n",
        "        self.state = self.paddle.rect.x\n",
        "    elif action == 1 : #stand still\n",
        "        pass\n",
        "    else : # right\n",
        "        if(self.paddle.rect.x + self.paddle.paddleWidth + self.paddle.speed > self.width):\n",
        "            self.paddle.rect.x = self.width - self.paddle.paddleWidth\n",
        "        else:\n",
        "            self.paddle.rect.x += self.paddle.speed\n",
        "        self.state = self.paddle.rect.x     \n",
        "\n",
        "    #reward for beiing at same position of the ball\n",
        "    if(self.ball.rect.x > self.paddle.rect.x and (self.ball.rect.x + self.ball.rad*2) < (self.paddle.rect.x + self.paddle.paddleWidth)):\n",
        "        reward = 1\n",
        "    else : \n",
        "        reward = -1\n",
        "\n",
        "    if(self.visualize == True):\n",
        "        #limit the clock\n",
        "        self.clock.tick(self.fps)\n",
        "        self.render()\n",
        "\n",
        "    # Check if game is done\n",
        "    if self._episode_ended == True: \n",
        "        return ts.termination(np.array(self._state, dtype=np.int32), reward)\n",
        "    else:\n",
        "        return ts.transition(np.array(self._state, dtype=np.int32), reward)"
      ],
      "metadata": {
        "id": "Z1q4EdBWMsqj"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instanciation de l'environnement python"
      ],
      "metadata": {
        "id": "OXKShXL2M9r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-- Create Python Environment --#\n",
        "env = BreakoutEnv(visualize=False) #add fps parameters if needed\n",
        "print('Action Spec:', env.action_spec())\n",
        "\n",
        "# check if python environement is correct\n",
        "print(\"validate python environment\")\n",
        "utils.validate_py_environment(env, episodes=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8svAovXM6fE",
        "outputId": "030fed60-2442-402a-b834-4b88cb4f9df3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Spec: BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action', minimum=0, maximum=2)\n",
            "validate python environment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test de l'environnement python"
      ],
      "metadata": {
        "id": "QOijKnvkNHlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Variables for testing environment\n",
        "num_episode = 10  # @param {type:\"integer\"}\n",
        "reward = 0 "
      ],
      "metadata": {
        "id": "P2FWVAsWNGxD"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-- Test with Python Environment pygame --#\n",
        "for i in range(num_episode):\n",
        "    time_step = env.reset()\n",
        "    #while episode not done\n",
        "    while not time_step.is_last():\n",
        "        #tensorFlow environment\n",
        "        action = np.random.randint(0,3)\n",
        "        time_step = env.step(action)\n",
        "        reward += time_step.reward\n",
        "    print(\"Episode \"+str(i+1)+\"/\"+str(num_episode)+ \" done : \" + str(env.score) + \n",
        "    \"/\" + str(env.wall.breakableBricks)+\" bricks\")\n",
        "\n",
        "print(\"reward:\",reward)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqKutEauNKM0",
        "outputId": "d43dc503-6f74-406f-928b-6af73d34c57f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1/10 done : 0/0 bricks\n",
            "Episode 2/10 done : 0/0 bricks\n",
            "Episode 3/10 done : 0/0 bricks\n",
            "Episode 4/10 done : 0/0 bricks\n",
            "Episode 5/10 done : 0/0 bricks\n",
            "Episode 6/10 done : 0/0 bricks\n",
            "Episode 7/10 done : 0/0 bricks\n",
            "Episode 8/10 done : 0/0 bricks\n",
            "Episode 9/10 done : 0/0 bricks\n",
            "Episode 10/10 done : 0/0 bricks\n",
            "reward: -9882.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversion vers un environnement TensorFlow"
      ],
      "metadata": {
        "id": "yoJdTTCrNUGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-- Convert in Tensor Environment --#\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "# Check if TensorFlow environment is correct\n",
        "print(isinstance(tf_env, tf_environment.TFEnvironment))\n",
        "print(\"TimeStep Specs:\", tf_env.time_step_spec())\n",
        "print(\"Action Specs:\", tf_env.action_spec())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fkzs4h0NRnH",
        "outputId": "709b2040-7e19-440e-b221-0e805360f83b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "TimeStep Specs: TimeStep(\n",
            "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
            " 'observation': BoundedTensorSpec(shape=(2,), dtype=tf.int32, name='observation', minimum=array(0, dtype=int32), maximum=array(640, dtype=int32)),\n",
            " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
            " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\n",
            "Action Specs: BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test de l'environnement TensorFlow"
      ],
      "metadata": {
        "id": "iB2Lqs7KNnab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-- Test  with Tensor Environment pygame --#\n",
        "for i in range(num_episode):\n",
        "    time_step = tf_env.reset()\n",
        "    #while episode not done\n",
        "    while not time_step.is_last():\n",
        "        #tensorFlow environment\n",
        "        action = tf.random.uniform(shape=[], minval=0, maxval=3, dtype=tf.int32)\n",
        "        time_step = tf_env.step(action)\n",
        "        reward += time_step.reward\n",
        "    print(\"Episode \"+str(i+1)+\"/\"+str(num_episode)+ \" done : \" + str(env.score) + \n",
        "    \"/\" + str(env.wall.breakableBricks)+\" bricks\")\n",
        "\n",
        "print(\"reward:\",reward.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixr-n8cqNnHU",
        "outputId": "fa14eec5-caa2-429c-ab8a-6a5acf7805cb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1/10 done : 0/0 bricks\n",
            "Episode 2/10 done : 0/0 bricks\n",
            "Episode 3/10 done : 0/0 bricks\n",
            "Episode 4/10 done : 0/0 bricks\n",
            "Episode 5/10 done : 0/0 bricks\n",
            "Episode 6/10 done : 0/0 bricks\n",
            "Episode 7/10 done : 0/0 bricks\n",
            "Episode 8/10 done : 0/0 bricks\n",
            "Episode 9/10 done : 0/0 bricks\n",
            "Episode 10/10 done : 0/0 bricks\n",
            "reward: [-20224.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrainement de l'IA"
      ],
      "metadata": {
        "id": "dbnfxlQ3NtWX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instanciation des environnements et conversion"
      ],
      "metadata": {
        "id": "g4iz2q4FOcGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic environment\n",
        "env = BreakoutEnv(visualize=False) #add fps parameters if needed\n",
        "\n",
        "#Create environment\n",
        "train_py_env = BreakoutEnv(visualize=False)\n",
        "eval_py_env = BreakoutEnv(visualize=False) \n",
        "\n",
        "#Convert into tf environment\n",
        "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env) "
      ],
      "metadata": {
        "id": "_TrNLfKFObCO"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Récupération des actions"
      ],
      "metadata": {
        "id": "rivmf2x1OjkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
        "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1"
      ],
      "metadata": {
        "id": "nU18S1C1Q_J_"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Création des couches"
      ],
      "metadata": {
        "id": "aqBE_YScRLlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "fc_layer_params = (100, 50) \n",
        "# Define a helper function to create Dense layers configured with the right\n",
        "# activation and kernel initializer.\n",
        "def dense_layer(num_units):\n",
        "  return tf.keras.layers.Dense(\n",
        "      num_units,\n",
        "      activation=tf.keras.activations.relu,\n",
        "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
        "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
        "\n",
        "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
        "# with `num_actions` units to generate one q_value per available action as\n",
        "# its output.\n",
        "\n",
        "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
        "q_values_layer = tf.keras.layers.Dense(\n",
        "    num_actions,\n",
        "    activation=None,\n",
        "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
        "        minval=-0.03, maxval=0.03),\n",
        "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
        "q_net = sequential.Sequential(dense_layers + [q_values_layer])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)"
      ],
      "metadata": {
        "id": "oYCoc447RKhq"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Création de l'agent DQN"
      ],
      "metadata": {
        "id": "ZapwqPmuRXAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use DQN agent to train IA\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()\n"
      ],
      "metadata": {
        "id": "13ekcWPuRV2p"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Création des polices"
      ],
      "metadata": {
        "id": "ZkSdyy7mRaqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Policies\n",
        "eval_policy = agent.policy\n",
        "collect_policy = agent.collect_policy\n",
        "\n",
        "#Create random policies\n",
        "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
        "                                                train_env.action_spec())\n",
        "time_step = train_env.reset()\n",
        "print(random_policy.action(time_step))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5djDhHuhRa3I",
        "outputId": "7da84e08-61b4-47f3-b789-23a08b136bfb"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>, state=(), info=())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fonction pour faire la moyenne des résultats "
      ],
      "metadata": {
        "id": "Dyc2FpORRguB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute average\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "  total_return = 0.0\n",
        "  for _ in range(num_episodes):\n",
        "\n",
        "    time_step = environment.reset()\n",
        "    episode_return = 0.0\n",
        "\n",
        "    while not time_step.is_last():\n",
        "      action_step = policy.action(time_step)\n",
        "      time_step = environment.step(action_step.action)\n",
        "      episode_return += time_step.reward\n",
        "    total_return += episode_return\n",
        "\n",
        "  avg_return = total_return / num_episodes\n",
        "  return avg_return.numpy()[0]"
      ],
      "metadata": {
        "id": "6OSGpgn2RgPj"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test avec la police aléatoire"
      ],
      "metadata": {
        "id": "NlKbCvICRmuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "#Test with random policy\n",
        "print(\"Test with random policy\")\n",
        "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axl0YA6mRqFH",
        "outputId": "806f9ab1-d6df-4e4d-c0cc-077706b4c524"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test with random policy\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1026.6"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Récupération des données via Reverb"
      ],
      "metadata": {
        "id": "7O__DpqMRpmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use Reverb to keep track of the data\n",
        "replay_buffer_max_length = 1000  # @param {type:\"integer\"}\n",
        "\n",
        "table_name = 'uniform_table'\n",
        "replay_buffer_signature = tensor_spec.from_spec(\n",
        "      agent.collect_data_spec)\n",
        "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
        "    replay_buffer_signature)\n",
        "\n",
        "table = reverb.Table(\n",
        "    table_name,\n",
        "    max_size=replay_buffer_max_length,\n",
        "    sampler=reverb.selectors.Uniform(),\n",
        "    remover=reverb.selectors.Fifo(),\n",
        "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
        "    signature=replay_buffer_signature)\n",
        "\n",
        "reverb_server = reverb.Server([table])\n",
        "\n",
        "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
        "    agent.collect_data_spec,\n",
        "    table_name=table_name,\n",
        "    sequence_length=2,\n",
        "    local_server=reverb_server)\n",
        "\n",
        "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
        "  replay_buffer.py_client,\n",
        "  table_name,\n",
        "  sequence_length=2)\n",
        "\n",
        "agent.collect_data_spec\n",
        "agent.collect_data_spec._fields"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWLpJrR-RxwB",
        "outputId": "1bfd7138-3960-401c-a548-1fa2f0def083"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('step_type',\n",
              " 'observation',\n",
              " 'action',\n",
              " 'policy_info',\n",
              " 'next_step_type',\n",
              " 'reward',\n",
              " 'discount')"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution avec la police aléatoire, afin d'obtenir des données initiales"
      ],
      "metadata": {
        "id": "n803-cyhSbqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Execution of the random policy in order to get data\n",
        "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
        "\n",
        "py_driver.PyDriver(\n",
        "    train_py_env, \n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      random_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=initial_collect_steps).run(train_py_env.reset())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Y3YcTHVShRd",
        "outputId": "a031e364-a44b-47de-dd4e-8f200f927e25"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TimeStep(\n",
              "{'discount': array(1., dtype=float32),\n",
              " 'observation': array([256, 310], dtype=int32),\n",
              " 'reward': array(-1., dtype=float32),\n",
              " 'step_type': array(1, dtype=int32)}),\n",
              " ())"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Création du Dataset pour permettre à l'agent de récuperer les informations obtenu via Reverb"
      ],
      "metadata": {
        "id": "xIxp_julSris"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a dataset in order to let the agent get access to the replay buffer\n",
        "batch_size = 64  # @param {type:\"integer\"}\n",
        "\n",
        "# Dataset generates trajectories with shape [Bx2x...]\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3,\n",
        "    sample_batch_size=batch_size,\n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "dataset\n",
        "\n",
        "iterator = iter(dataset)\n",
        "# print(iterator)"
      ],
      "metadata": {
        "id": "kQDuUeWkSltv"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrainement de l'agent"
      ],
      "metadata": {
        "id": "TO4J1PTrSwFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimisation"
      ],
      "metadata": {
        "id": "UNFy9pRUS3T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the agent\n",
        "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
        "agent.train = common.function(agent.train)"
      ],
      "metadata": {
        "id": "6XUvTagsSwYl"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remise à zéro de l'agent"
      ],
      "metadata": {
        "id": "rpwBF8acS9W9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset the train step.\n",
        "agent.train_step_counter.assign(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PLA0NZfS9QN",
        "outputId": "d0c65e10-91be-4102-a606-a9a63e80fce7"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=() dtype=int32, numpy=0>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation de la police de l'environnement avant l'entrainement"
      ],
      "metadata": {
        "id": "ThYs5D7US89p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the agent's policy once before training.\n",
        "print(\"Evaluate the agent's policy once before training\")\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "# Reset the environment.\n",
        "time_step = train_py_env.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTCvbY7FS8w0",
        "outputId": "06129695-49fd-4156-f1c8-20e1427a41db"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluate the agent's policy once before training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrainement"
      ],
      "metadata": {
        "id": "YcEIQnjkTQGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the agent for num_terations\n",
        "num_iterations = 10000 # @param {type:\"integer\"}\n",
        "collect_steps_per_iteration =   1# @param {type:\"integer\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "eval_interval = 1000  # @param {type:\"integer\"}\n",
        "\n",
        "# Create a driver to collect experience.\n",
        "collect_driver = py_driver.PyDriver(\n",
        "    train_py_env,\n",
        "    py_tf_eager_policy.PyTFEagerPolicy(\n",
        "      agent.collect_policy, use_tf_function=True),\n",
        "    [rb_observer],\n",
        "    max_steps=collect_steps_per_iteration)\n",
        "\n",
        "print(\"Beginning of the training\")\n",
        "for _ in range(num_iterations):\n",
        "\n",
        "  # Collect a few steps and save to the replay buffer.\n",
        "  time_step, _ = collect_driver.run(time_step)\n",
        "\n",
        "  # Sample a batch of data from the buffer and update the agent's network.\n",
        "  experience, unused_info = next(iterator)\n",
        "  train_loss = agent.train(experience).loss\n",
        "\n",
        "  step = agent.train_step_counter.numpy()\n",
        "\n",
        "  if step % log_interval == 0:\n",
        "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "  if step % eval_interval == 0:\n",
        "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "    returns.append(avg_return)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FUqsW66S25V",
        "outputId": "e879c0e1-efc9-4179-e1c0-fc9d55a1a8c4"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning of the training\n",
            "step = 200: loss = 0.8887037038803101\n",
            "step = 400: loss = 1.1925010681152344\n",
            "step = 600: loss = 1.1270884275436401\n",
            "step = 800: loss = 0.7557409405708313\n",
            "step = 1000: loss = 0.8863093852996826\n",
            "step = 1000: Average Return = -758.7999877929688\n",
            "step = 1200: loss = 0.7953554391860962\n",
            "step = 1400: loss = 0.7805172801017761\n",
            "step = 1600: loss = 0.7291388511657715\n",
            "step = 1800: loss = 239.0775909423828\n",
            "step = 2000: loss = 0.9776034355163574\n",
            "step = 2000: Average Return = -759.0\n",
            "step = 2200: loss = 0.8822107315063477\n",
            "step = 2400: loss = 0.9160993099212646\n",
            "step = 2600: loss = 1.4934208393096924\n",
            "step = 2800: loss = 0.7139556407928467\n",
            "step = 3000: loss = 0.6415138840675354\n",
            "step = 3000: Average Return = -926.4000244140625\n",
            "step = 3200: loss = 0.8376051187515259\n",
            "step = 3400: loss = 1.5571699142456055\n",
            "step = 3600: loss = 0.7975170612335205\n",
            "step = 3800: loss = 1.1006065607070923\n",
            "step = 4000: loss = 0.9181529879570007\n",
            "step = 4000: Average Return = -1769.800048828125\n",
            "step = 4200: loss = 1.1649250984191895\n",
            "step = 4400: loss = 0.9121420979499817\n",
            "step = 4600: loss = 1.3153626918792725\n",
            "step = 4800: loss = 0.9322020411491394\n",
            "step = 5000: loss = 0.9688862562179565\n",
            "step = 5000: Average Return = -758.4000244140625\n",
            "step = 5200: loss = 0.9039346575737\n",
            "step = 5400: loss = 0.9839047193527222\n",
            "step = 5600: loss = 0.8855574131011963\n",
            "step = 5800: loss = 0.9278199672698975\n",
            "step = 6000: loss = 34.54499816894531\n",
            "step = 6000: Average Return = -759.0\n",
            "step = 6200: loss = 0.9405277371406555\n",
            "step = 6400: loss = 1.2742961645126343\n",
            "step = 6600: loss = 0.8906455039978027\n",
            "step = 6800: loss = 1.1058841943740845\n",
            "step = 7000: loss = 0.9476557970046997\n",
            "step = 7000: Average Return = -759.0\n",
            "step = 7200: loss = 2.35298752784729\n",
            "step = 7400: loss = 0.9928287863731384\n",
            "step = 7600: loss = 0.858815610408783\n",
            "step = 7800: loss = 1.020127534866333\n",
            "step = 8000: loss = 319.36822509765625\n",
            "step = 8000: Average Return = -1769.800048828125\n",
            "step = 8200: loss = 95999.265625\n",
            "step = 8400: loss = 296044.40625\n",
            "step = 8600: loss = 528984.875\n",
            "step = 8800: loss = 123232.8125\n",
            "step = 9000: loss = 176712.453125\n",
            "step = 9000: Average Return = -1770.0\n",
            "step = 9200: loss = 4404076.0\n",
            "step = 9400: loss = 537.01123046875\n",
            "step = 9600: loss = 109.38916015625\n",
            "step = 9800: loss = 37371.80859375\n",
            "step = 10000: loss = 27.09765625\n",
            "step = 10000: Average Return = -1770.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Création d'un graphe pour visualiser l'entrainement de l'agent"
      ],
      "metadata": {
        "id": "fx5LwEfhTXe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the plot \n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "rVolAUYsTX3c",
        "outputId": "912a175e-9b33-45f6-da6e-1bf1e21176bb"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1820.5799987792968, 250.0)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test de l'agent après l'entaienement"
      ],
      "metadata": {
        "id": "m72ncjN3TfKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test after training\n",
        "test_py_env = BreakoutEnv(visualize=False) \n",
        "\n",
        "#Convert into tf environment\n",
        "test_env = tf_py_environment.TFPyEnvironment(test_py_env)\n",
        "avg_return = compute_avg_return(test_env, agent.policy, num_eval_episodes)\n",
        "print(\"results\",avg_return)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL-CwpsGTexc",
        "outputId": "c5a19a66-a853-4dca-9a35-b865a93e8818"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results -1769.8\n"
          ]
        }
      ]
    }
  ]
}